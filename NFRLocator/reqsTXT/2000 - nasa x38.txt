SOFTWARE REQUIREMENTS SPECIFICATION / INTERFACE REQUIREMENTS SPECIFICATION for the X-38 Fault Tolerant System Services Contract No.
NAS 9-97216 DRL Sequence Nos.
12/14 12 April 2000 Prepared for: National Aeronautics and Space Administration Lyndon B.
Johnson Space Center 2101 NASA Road 1 Houston, Texas 77058-3696 Prepared by: The Charles Stark Draper Laboratory, Inc.
555 Technology Square Cambridge, Massachusetts 02139 Cage Code: 51993 DISTRIBUTION STATEMENT [A] [Approved for public release; distribution is unlimited] SOFTWARE REQUIREMENTS SPECIFICATION / INTERFACE REQUIREMENTS SPECIFICATION for the X-38 Fault Tolerant System Services Approved by: RECORD OF REVISIONS Rev Result of Pages Affected Approval/Date ? ECR 0079A Initial Release L.S.A.
5/4/00 A ECR 0112 Revision due to Updated FTTP Specifications RR 24 Aug 2000 B ECR 134 Revision due to Updated FTTP Specifications RR 22 Dec 2000 C ECR148 Revision due to NASA Comments and Updated FTPP Requirements Document RR 14 Mar 2001 D ECR182 Revision due to NASA Comments and Updated FTPP Requirements Document RR 2 Jul 2001 E ECR190 Revision due to NASA Comments RR 10 Aug 2001 F ECR0226 Updated Requirements Traceability table, pages 65, 67, 68, 74, 83, 84, 86 TABLE OF CONTENTS 1.
SCOPE	1 1.1	Identification	1 1.2	System Overview	1 1.3	Document Overview	4 2.
REFERENCED DOCUMENTS	6 2.1	Government Documents	6 2.2	Non-Government Documents	6 3.
REQUIREMENTS	7 3.1	Required States and Modes	7 3.2	CSCI Capability Requirements	8 3.2.1	System Initialization	8 3.2.2	Scheduling Services	9 3.2.2.1	Scheduling Execution	9 3.2.2.2	Task and Rate Group Execution	11 3.2.2.3	Exception Handling	12 3.2.3	Memory Management Services	13 3.2.3.1	Memory Protection	13 3.2.4	Communication Services	13 3.2.4.1	Sockets	14 3.2.4.1.1	Message Queue Sockets	15 3.2.4.1.2	Pipe Sockets	16 3.2.5	Fault Detection and Isolation	17 3.2.5.1	Initial BIT	17 3.2.5.2	Continuous BIT	20 3.2.5.3	RAM Scrub	21 3.2.6	Redundancy Management	21 3.2.6.1	Virtual Group Configuration	22 3.2.6.2	Recovery	22 3.2.6.2.1	Recovery from Processor Failure	26 3.2.6.2.2	Recovery from Link Failure	28 3.2.6.2.3	Recovery from Network Element Failure	28 3.2.7	Time Services	28 3.2.8	System Support Services	29 3.2.8.1	CTC Requirements	29 3.2.8.1.1	Telemetry Requirements	30 3.2.8.1.2	Command Read Requirements	30 3.2.9	Power Down Services	30 3.3	CSCI External Interface Requirements	30 3.3.1	Interface Identification and Diagram	30 3.3.2	IRIG-B/FTSS Interfaces	31 3.3.3	API/FTSS Interfaces	31 3.3.4	Network Element/FTSS Interfaces	32 3.3.5	Radstone/FTSS Interfaces	36 3.3.6	VxWorks/FTSS Interfaces	36 3.3.7	Multi-Protocol Communications Controller (MPCC)/FTSS Interfaces	36 3.3.8	FCP-ICP/FTSS Interfaces	37 3.4	CSCI Internal Interface Requirements	38 3.5	CSCI Internal Data Requirements	38 3.6	Adaptation Requirements	38 3.7	Safety Requirements	38 3.8	Security and Privacy Requirements	38 3.9	CSCI Environment Requirements	38 3.10	Computer Resource Requirements	39 3.10.1	Computer Hardware Requirements	39 3.10.2	Computer Hardware Resource Utilization Requirements	39 3.10.3	Computer Software Requirements	40 3.10.4	Computer Communications Requirements	40 3.11	Software Quality Factors	40 3.12	Design and Implementation Constraints	40 3.13	Personnel-related Requirements	40 3.14	Training-related Requirements	40 3.15	Logistics-related Requirements	40 3.16	Other Requirements	40 3.16.1	ICP Services	41 3.17	Packaging Requirements	42 3.18	Precedence and Criticality of Requirements	42 4.
QUALIFICATION PROVISIONS	43 5.
REQUIREMENTS TRACEABILITY	44 6.
NOTES	91 6.1	List of Acronyms	91 6.2	Glossary	92 Figure Page Figure 11 FCC Virtual Architecture.
2 Figure 12.
FCC Software Architecture.
3 Figure 31.
Fault Tolerant System Services States.
7 Figure 32 Fault-down Map	23 Figure 33 Fault Tolerant System Services CSCI External Interfaces.
31 Figure 34.
Network Element Interfaces to FTSS CSCI.
32 LIST OF TABLES Table Page Table 3.2-1.
Software Exception Mapping Table.
12 Table 3.2-2.
FCP IBIT Table.
18 Table 3.2-3 ICP IBIT Table	19 Table 3.2-4.
ICP/PMC1553 IBIT Test Configuration.
20 Table 3.2-5.
MPCC IBIT Test Configuration.
20 Table 3.3-1.
Network Element Descriptor Block Interface.
33 Table 3.3-2.
Network Element Data Block Interface.
34 Table 3.3-3.
Data Element Definition Table for Radstone/FTSS Interfaces.
36 Table 3.3-4.
Data Element Definition Table for FTSS Scheduler Interface.
38 Table 5-1.
FTPP to SRS Trace Table.
44 1.
1.
SCOPE 1.1 Identification This Software Requirements Specification/Interface Requirements Specification (SRS/IRS), Draper document number 297749, defines the software requirements and the external interface requirements for the Fault Tolerant System Services (FTSS) Computer Software Configuration Item (CSCI).
1.2 System Overview The central part of the avionics architecture of NASA's X-38 Crew Return Vehicle is a quad-redundant Flight Critical Computer (FCC) which is based on Draper's Fault Tolerant Parallel Processor (FTPP) architecture.
The FCC consists of four Flight Critical Processors (FCPs) operating as a quad-redundant Virtual Group (VG), five simplex Instrument Control Processors (ICPs) running as five separate VGs, five Draper Network Elements (NEs), four Multi-protocol/RS-422-cards, sixteen Digital I/O (DIO) cards, four Analog I/O cards, and four Decomm cards.
The FCPs, operating as a single, quad-redundant set, function as the main application processor.
A complete suite of Fault Tolerant System Services (FTSS) software will be loaded onto the FCPs and provide an Application Programming Interface (API) between NASA's application code and the underlying hardware (Motorola Power PCs) and a COTS operating system (VxWorks).
The FTSS software provides Scheduling Services, Communication Services, Time Services, Memory Management Services, Fault Detection and Isolation, Redundancy Management, System Support Services, and a Mission Management template.
A reduced set of FTSS Communications Services will be loaded onto each ICP and will provide an API between the I/O software running on the ICPs and the NEs.
Figure 1-1 is a high-level block diagram of the FCC virtual hardware configuration.
Figure 1-2 is a high-level block diagram of the FCC software architecture.
Figure 11 FCC Virtual Architecture.
Figure 12.
FCC Software Architecture.
1.1 1.3 Document Overview This specification defines the software requirements and the interface requirements for the FTSS CSCI.
It has been prepared using MIL-STD-498 and DI-IPSC-81433 and DI-IPSC-81434 for guidance.
This SRS/IRS is organized as follows: 1.
Section 1 - Scope: identifies the CSCI that this specification pertains to, provides an overview of FTSS, and provides an overview of this specification.
2.
Section 2 - Referenced Documents: provides a list of documents referenced in this specification.
3.
Section 3 - Requirements: specifies the engineering requirements for the FTSS CSCI a) Section 3.1 describes the CSCI required states and modes.
b) Section 3.2 specifies the CSCI software requirements for each capability as follows: i) 3.2.1 System Initialization ii) 3.2.2 Scheduling Services iii) 3.2.3 Memory Management Services iv) 3.2.4 Communication Services v) 3.2.5 Fault Detection and Isolation vi) 3.2.6 Redundancy Management vii) 3.2.7 Time Services viii) 3.2.8 System Support Services c) Section 3.3 describes the CSCI external interface requirements.
d) Section 3.4 identifies internal interface requirements.
e) Section 3.5 identifies internal data requirements.
f) Section 3.6 identifies the adaptation requirements.
g) Section 3.7 presents safety requirements.
h) Section 3.8 presents security and privacy requirements.
i) Section 3.9 discusses environment requirements.
j) Section 3.10 identifies computer resource requirements.
k) Section 3.11 describes software quality factors.
l) Section 3.12 identifies design and implementation constraints.
m) Section 3.13 identifies personnel requirements.
n) Section 3.14 identifies training-related requirements.
o) Section 3.15 identifies logistics-related requirements.
p) Section 3.16 identifies other requirements.
q) Section 3.17 presents packaging requirements.
r) Section 3.18 identifies precedence and criticality requirements.
4.
Section 4 - Qualification provisions: defines a set of qualification methods and specifies for each requirement in Section 3 the method(s) to be used to ensure that the requirement has been met.
5.
Section 5 - Requirements Traceability: provides a summary of traceability between system requirements expressed in the X-38 Fault Tolerant Parallel Processor Requirements document and the requirements elaborated in Section 3 of this document.
6.
Section 6 - Notes: provides a list of acronyms and a glossary of terms used throughout this document.
2.
REFERENCED DOCUMENTS The following documents of the exact issue shown, or current issue if not shown, form a part of this specification to the extent specified herein.
This document is directly traceable to the X-38 Fault Tolerant Parallel Processor Requirements document.
In the event of conflict between that document and the contents of this specification, Draper will propose resolution of the conflict to NASA for approval.
All references to API in this document refer to Draper document number 297752, Application Programming Interface for the X-38 Fault Tolerant System Services.
3.
REQUIREMENTS 3.1 Required States and Modes Fault Tolerant System Services CSCI states are shown in Figure 3-1.
Figure 31.
Fault Tolerant System Services States.
System Initialization is entered when the system is powered up for the first time, or when a power-on reset exception is received by the software.
Section 3.2.1 gives the requirements for this state.
The system transfers to the Normal Operation state after the FCP has been configured into a fault-tolerant computer and enables the timer interrupt.
In the Normal Operation state the software meets the performance and functional requirements (other than those listed as System Initialization requirements) in the no-fault case.
The system will transfer to the System Initialization state if a reset exception is received.
The system will transfer to the Fault Recovery state if a fault is detected.
In the Fault Recovery state the system is reconfigured.
If a single permanent fault has occurred, for example, the system will, when the transfer is made back to Normal Operation state, be capable of handling another fault.
The requirements for this state are found in Section 3.2.6.2 and its subsections.
3.2 CSCI Capability Requirements 3.2.1 System Initialization System Initialization performs those functions necessary to transform the hardware consisting of the FCP processors, network elements, and on-board I/O devices into a real time system executing tasks with fault tolerant message exchanges.
1.
Whenever a power-on reset occurs, System Initialization shall [SRS194] perform the following functions.
2.
As part of System Initialization , the Boot ROM shall [SRS234] be configured to, after completing IBIT, call the manufacturer-supplied VxWorks Board Support Package (BSP) initialization software followed by a call to the FTSS System Initialization software.
3.
System Initialization shall [SRS014] initiate the watchdog timer.
4.
System Initialization shall [SRS292] enable and reset the processor�s watchdog timer such that, in the absence of a fault, the watchdog timer does not expire and reset the processor..
5.
System Initialization shall [SRS008] synchronize the FCP virtual group in the presence of a power on skew of 2.5 seconds.
6.
System Initialization shall [SRS010] configure the FCP virtual group to use all available synchronized processors, if at least 3 of the 5 FCRs are active.
7.
If any of the FCP processors are not synchronized, System Initialization in the surviving triplex shall [SRS177] attempt to sync with the failed FCP.
8.
If the failed FCP processor has not synced in 2.5 seconds after the surviving triplex has detected the loss of the FCP, then the surviving triplex shall [SRS178], within 1 second, send a single voted VMEbus reset through the NE to the failed FCP.
9.
System Initialization shall [SRS011] align processor state and congruent aligned memory locations.
Processor state includes all registers.
It also includes those timers used by FTSS.
10.
The FCP shall [SRS296] configure ICP simplex virtual groups for each channel in the FCP virtual group.
11.
The FCP shall [SRS297] wait up to 15 seconds, after configuring the ICP virtual groups, for communication to start from the ICP.
The application can use this time on the ICP to initialize I/O boards.
12.
System Initialization shall [SRS215] call an application initialization function to allow the application to (at least) create tasks, create communication sockets, initialize the vehicle mode, and initialize memory alignment allowance.
13.
The FCP shall [SRS221], after application initialization is complete, send an FCP Ready Sync message to the ICP 14.
The FCP shall [SRS189] wait up to 2.5 seconds (from the sending of the FCP Ready Sync) for the ICP Ready signal.
Note that FTSS will not fail the FCR if this signal is not received within this time.
FTSS will wait until the normal ICP presence test fails.
15.
The FCP shall [SRS243], if the NEFU ICP fails to send its ICP Ready signal, mask out that ICP, but continue to use the NE.
16.
System Initialization shall [SRS199], when all other activities are completed, start the 50 Hz timer and enable the timer interrupt.
This will allow the interrupt handler to initiate normal activities.
17.
System Initialization, from hardware reset to starting of the 50 Hz timer, shall [SRS015] take no longer than 1.5 minutes.
3.2.2 Scheduling Services 3.2.2.1 Scheduling Execution Whenever the 50 Hz timer interrupt occurs, the interrupt handler invokes the scheduler (there are various ways to implement this invocation, such as using a procedure call or by setting an event; no specific implementation is to be inferred).
The scheduler allows the application to create lists of tasks that run during a given segment of time, at various rates.
The application can create "vehicle modes" to designate a unique segment.
The application can also set up "rate groups".
Each rate group has some number of tasks associated with it, and it also has a rate for those tasks.
Note that there may be some number of rate groups that have the same rate.
These contain the tasks that will run at that rate in different vehicle modes.
Some number of rate groups can be associated with a given vehicle mode.
When an API call is made to change the vehicle mode, the scheduler will disable the tasks associated with all the rate groups in the old vehicle mode, and enable the tasks associated with all the rate groups in the new vehicle mode.
The enabled tasks are then unblocked at the rate given in its associated rate group.
An API call is available for the task to call to block itself when it is finished with its cyclic processing.
1.
The scheduler shall [SRS017] provide an API call to install a task into a rate group.
The API call is invoked during system initialization.
2.
The scheduler shall [SRS196] support up to 20 tasks per rate group.
3.
The scheduler shall [SRS018] provide an API call to install a rate group into a vehicle mode at system initialization.
4.
The scheduler shall [SRS197] support up to 3 rate groups per vehicle mode.
5.
The scheduler shall [SRS195] support up to 5 vehicle modes.
6.
The FTSS software shall [SRS002] provide the identical services in all vehicle modes.
7.
The scheduler shall [SRS019] provide an API call for an FCP application task to alert the scheduler of a vehicle mode change.
8.
The scheduler shall [SRS020] complete the change from one vehicle mode to the next within 1.02 seconds.
There is up to a full major frame from notification of an impending mode change to acting on it in minor frame 0 of the next major frame plus the time it takes during the next minor frame 0 to switch tasking.
9.
The scheduler shall [SRS021] process vehicle mode changes during minor frame 49.
10.
The scheduler shall [SRS022] execute cyclic tasks, providing an API call to allow the application to block until its next iteration.
11.
The scheduler shall [SRS024] execute as the highest priority FTSS or application task in the system.
12.
The scheduler shall [SRS025] keep a minor frame count from 0 to 49.
13.
The scheduler shall [SRS027] give tasks priority values according to their rate - the higher the rate, the higher the priority.
14.
The scheduler shall [SRS028] detect 50 Hz, 10 Hz and 1 Hz rate group over-runs.
15.
The scheduler shall [SRS029] report rate group over-runs to the application via an API service for incorporation in the telemetry data stream.
16.
The scheduler shall [SRS216] provide an API call to specify which task was running within the rate group which over-ran.
17.
The scheduler shall [SRS030] provide a mechanism to inform a task when it did not complete during the previous frame and restart it at the beginning of the task.
18.
The scheduler shall [SRS181] set the 50 Hz interval timer to a count down value so as to cause the next minor frame interrupt at 20 msec from the previous interrupt congruently in all operational FCPs.
19.
The scheduler shall [SRS032] issue a 50 Hz interrupt to the ICPs by means of a VMEbus IRQ5 interrupt.
20.
The scheduler shall [SRS191] issue the 50 Hz interrupt to all the ICPs with a skew no greater than 330 microseconds.
21.
The scheduler shall [SRS033] send the minor frame number, vehicle mode, mission elapsed time (MET), and separation elapsed time (SEP) to the ICP prior to the 50 Hz interrupt.
Note: The NE unique identifier (NE ID) is available to the ICPs via the ftss_my_icp() API call.
22.
The scheduler shall [SRS034] take no longer than 1 millisecond to execute scheduler and Time Services FTSS overhead tasks in each rate group.
This means that the time from the 50 Hz timer interrupt to the start of the first task in the 50 Hz rate group will be less than or equal to 1 millisecond, assuming 27 packets of data need to be delivered.
23.
The FTSS software shall [SRS278] provide an API call that provides the application program the minor frame number.
The behavior of synchronous tasks executed by the scheduler must be deterministic.
3.2.2.2 Task and Rate Group Execution 1.
The scheduler shall [SRS035] provide rate groups that execute at 50 Hz, 10 Hz and 1 Hz., with a drift rate no greater than 50 microseconds per second, and with a jitter no greater than 330 microseconds.
2.
The scheduler shall [SRS037] provide a method to schedule tasks at a set rate and in a set order within the rate group.
3.
The scheduler shall [SRS198] execute all the tasks in each of the rate groups that have been installed in the current mode.
4.
The scheduler shall [SRS039] rely on the order used in adding tasks to a rate group to determine the task priorities.
5.
The scheduler shall [SRS042] provide a method for a task to be scheduled as a 50 Hz "helper" task for source congruency input exchanges and voted output exchanges that starts in a particular minor frame but runs only during every 5th or 50th minor frame, effectively running at a lower, sub-rate, 10 Hz or 1 Hz, respectively.
6.
The scheduler shall [SRS270] provide a task deadline capability that allows the application to specify which minor frame a task should start in and finish in.
All tasks in rate groups and their corresponding schedules for all vehicle modes will be setup at system initialization.
Tasks in a rate group must suspend on a scheduler API call at the top of their execution loop.
3.2.2.3 Exception Handling For purposes of handling exceptions, exceptions are defined as either software or hardware exceptions.
Software exceptions are defined as those mapped into VxWorks signals.
All other exceptions are classified as hardware exceptions.
Table 3.2-1 shows the mapping of software exceptions to VxWorks signals.
1.
Upon the occurrence of an exception of either kind (hardware or software), the FCP shall [SRS172] make the error type available to the application, via an API service, for incorporation in the telemetry stream and include all context data relevant to the exception, namely the contents of the Machine State Register (MSR), and the machine status Save/Restore Registers (SRR0 & SRR1).
2.
The scheduler shall [SRS031] provide a mechanism for a task optionally to define a user written software-exception-handling routine that runs in the context of the task.
3.
For hardware exceptions and reserved exceptions, the FTSS shall [SRS276] make the error type and its context data available to the application, then return from the exception handler to the task that was running when the exception occurred.
4.
For software exceptions occurring within the FTSS, the FTSS shall [SRS277] make the error type and its context data available to the application, then restart the offending task at its beginning.
5.
For other software exceptions, regardless of whether or not a user written exception handling routine is invoked, if an exception occurs, the scheduler shall [SRS173], after making available the error type and context data to the application, resume processing (after the exception-handling routine runs, if provided) at the initialization point of the offending task.
6.
For software exceptions occurring during Startup, FTSS shall [SRS301] issue a VME reset to the FCR in which the exception occurred.
3.2.3 Memory Management Services 3.2.3.1 Memory Protection There are two types of memory violations that might occur: 1) as a result of a hardware fault or SEU and 2) as a result of a common mode (usually, software) error.
Memory violations that result from random hardware faults will be detected in the same way as any other hardware fault is detected in the FTPP and don't require memory protection for them to be detected and dealt with.
In the second case, NASA has determined that however the memory protection function is implemented, the policy will be to restart the task that is executing when a memory violation (exception) is detected.
The watchdog timer and ground based testing will uncover some but not all of the possible memory faults.
3.2.4 Communication Services The FTSS communication services provide message-passing capabilities that are layered on top of the packet based network element communication hardware.
Messages are contiguous blocks of variable length data that are transferred from one task to another.
Messages are addressed with a global unique communication identifier that routes them to the appropriate virtual group (VG) and socket.
Associated with the message are descriptor fields describing the sender, receiver, the type of message, and how the message is to be exchanged.
The unique identifier for an end point consists of a virtual group identifier and a socket identifier.
The sending and receiving end points may live on the same virtual group or on different virtual groups.
Communication Services are divided into two constituent capabilities: "Synchronous" message services and "Immediate" message services.
"Synchronous" message services send and receive data on rate group frame boundaries; thus allowing safe inter-rate group communication.
"Synchronous" message services are provided by message queue sockets.
"Immediate" message services unlike "synchronous" message services initiate a message transfer immediately.
When used for inter-VG communication, "immediate" message services interface directly with the Byzantine Resilient Virtual Circuit (BRVC) abstraction level communications interface and force an immediate network element access.
"Immediate" message passing between virtual groups is restricted to the highest priority rate group on the FCP.
This restriction does not apply to the ICPs.
"Immediate" message passing within a virtual group is not restricted to the highest rate group, but must be used carefully by the application to prevent desynchronization.
"Pipe" sockets provide "Immediate" message services.
Communication services provide a message passing capability that guarantees congruent use of the network element among the members of a virtual group under fault free conditions.
1.
Communication services shall [SRS047] provide "synchronous" message passing services in the form of "message queues".
2.
Communication services shall [SRS048] provide "immediate" message passing services in the form of "pipes".
"Pipes" provide fast data throughput between virtual groups or within a virtual group when minimal data latency is necessary.
3.
Communication services shall [SRS049] provide the capability to "broadcast" messages to all virtual groups.
4.
Communication services shall [SRS050] restrict the use of "immediate" message passing services between virtual groups (from FCP to ICP) to tasks running in the highest rate group on the FCP.
This restriction does NOT apply to the ICPs since they are running as simplex VGs.
5.
Communication services shall [SRS051] detect message passing between application tasks living on the same virtual group and bypass the usage of the network element.
6.
Communication services shall [SRS052] route messages to the proper virtual group(s) and socket.
7.
Communication services shall [SRS053] deliver messages in the same order at each member of a virtual group.
8.
Communication services shall [SRS054] perform synchronous message passing at rate group frame boundaries.
This ensures that all redundant instantiations of a given rate group task have consistent messages throughout the rate group frame.
9.
Communication services shall [SRS235] detect a babbling NE or ICP within 20 milliseconds of the receipt of the first erroneous packet.
10.
FTSS shall [SRS255] mask out a babbling NE or ICP within 40 milliseconds after it is detected.
3.2.4.1 Sockets Sockets are the end points of FTSS communication, which provide a transparent interface to the BRVC communications layer and a useful interface to the application layer.
Sockets maintain the buffers between the underlying packet based communication primitives that directly access the network elements and the message based communication services used by the rate group tasks.
Sockets used for "synchronous" message passing behave differently than those used for "immediate" message passing.
1.
Synchronous message passing sockets shall [SRS055] queue outgoing messages until they are transmitted at frame boundaries.
The "create" and "open" API calls for synchronous sockets allow the application to specify the maximum message size and how many incoming messages the socket may buffer.
2.
If there is insufficient space to enqueue a message for transmission, Communication services shall [SRS059] return an error to the corresponding task.
Sockets are non-blocking and place the burden of polling on the application task.
3.2.4.1.1 Message Queue Sockets Message queue sockets allow a single task to queue a variable number of messages, each of variable length.
One task is allowed to receive messages from this queue.
Message queue sockets define a dedicated communication path between two tasks with guaranteed message delivery.
Message queue sockets provide "synchronous" communication and perform sending/receiving of messages at frame boundaries.
1.
Communication services shall [SRS062] provide a message queue communication mechanism that guarantees message delivery between a sending and receiving task.
2.
Communication services shall [SRS063] provide an API for "message queue" communication.
3.
Communication services shall [SRS064] provide the following error handling information as feedback to the "message queue" API calls: a) notification of invalid or out of range application specified parameters on all operations, b) notification of an attempt to create a broadcast message queue, c) message queue "open" of end point ( SENDER/RECEIVER ) by non-assigned virtual group, d) message queue is full when performing a send operation, e) connection/transmission error, f) FTSS unable to create/open message queue, and g) notification that a received message was truncated to the buffer size provided.
4.
The message queue "create" API requires the application to specify the sending and receiving virtual group identifiers.
Communication services shall [SRS066] only allow a single task living on each specified virtual group to "open" the respective end of the queue.
3.2.4.1.2 Pipe Sockets "Pipe" sockets are used for "immediate" communication.
They may be created with a broadcast capability.
Pipes may only be opened by one sending task.
Pipes may be opened by multiple receiving tasks if they are created with the "broadcast" capability; otherwise they may only be opened by one receiving task.
Pipes are the only broadcast mechanism available to the application.
1.
Communication services shall [SRS067] provide a "pipe" communication mechanism allowing immediate message passing through the network and allowing a 50hz FCP transfer task to poll until it can read an immediate message from the ICP.
2.
Communication services shall [SRS068] provide an API for "pipe" communication.
3.
Communication services shall [SRS069] provide the capability to create "pipe"s which "broadcast" their messages to all virtual groups.
4.
Communication services shall [SRS070] provide the following error handling information as feedback to the "pipe" API calls: a) notification of invalid or out of range application specified parameters on all operations, b) notification of an attempt to create a broadcast pipe with an ICP as the sending virtual group, c) pipe "open" of end point ( SENDER/RECEIVER ) by non-assigned virtual group, d) notification upon receiving a message that the previous message was overwritten, e) connection/transmission error, f) FTSS unable to create/open pipe, and g) notification that a received message was truncated to the buffer size provided.
5.
If the broadcast option is used, each virtual group should open the pipe and read from it to avoid flow control problems.
6.
The "pipe" "create" API requires the application to specify the sending and receiving virtual group identifiers.
Communication services shall [SRS073] only allow a single task living on each specified virtual group to "open" the respective end of the pipe.
In the case of a broadcast "pipe", communication services allows one task in each virtual group of the system to open the receiving end of the "pipe".
3.2.5 Fault Detection and Isolation Fault Detection and Isolation (FDI) provides the capability to detect and diagnose faults within FCC hardware.
The functionality of FDI is decomposed into 2 capabilities-Initial Built-In Test (IBIT) and Continuous BIT (CBIT).
FDI IBIT provides the facilities for the detection and diagnosis of faults during system initialization (at power on or CPU reset) on FCPs, ICPs, PMC 1553s, and MPCCs.
FDI CBIT provides the facilities for the detection and diagnosis of faults on FCPs during all operational phases.
In general, these tests execute system-wide tests using the fault tolerance characteristics of the FTPP architecture.
3.2.5.1 Initial BIT Initial BIT constitutes a series of self-tests provided by the manufacturer of the equipment being tested.
Initial BIT tests constitute tests of the processors, and I/O devices.
Note that by configuring the network elements to automatically enter ISYNC on Power Up, there is no opportunity to perform IBIT on the NEs.
The fact that an NE is in sync with the other NEs will have to substitute for a separate NE IBIT function.
FTSS IBIT executes on the Flight Control Processors (FCPs) at system initialization.
These tests exercise the functionality of the various system components.
1.
The FTSS software shall [SRS237] configure the FCP to act as the Radstone IBIT master, with the exception that the ICP on the NEFU is the master.
2.
Requirement deleted.
3.
The FTSS shall [SRS260] configure each FCP to perform IBIT Minimum Processing Environment (MPE) Tests, Power-up Tests, and Initial BIT on each FCP, as shown inTable 3.2-2.
.
4.
The FTSS shall [SRS261] configure each FCP to halt processing if any of the MPE tests fail.
5.
The FTSS shall [SRS262] configure each FCP to continue processing if any of the Power-up or Initial BIT tests fail.
6.
The FTSS shall [SRS287] configure each ICP to perform IBIT Minimum Processing Environment (MPE) Tests, Power-up Tests, and Initial BIT on each ICP, as shown inTable 3.2-3.
7.
The FTSS shall [SRS288] configure each ICP to halt processing if any of the MPE tests fail.
8.
The FTSS shall [SRS289] configure each ICP to continue processing if any of the Power-up or Initial BIT tests fail.
9.
The FTSS shall [SRS264] configure each ICP/PMC1553 to perform IBIT MPE Tests and Initial BIT as shown in Table 3.2-4.
10.
The FTSS shall [SRS265] configure each ICP/PMC1553 to halt processing if any of the MPE tests fail.
11.
The FTSS shall [SRS266] configure each ICP/PMC1553 to continue processing if any of the Initial BIT tests fail.
12.
The FTSS shall [SRS267] configure each MPCC to perform MPE Tests as shown in Table 3.2-5.
13.
Each MPCC is configured to halt processing if any of the MPE tests, listed in Table 3.2-5, fails.
14.
When the IBIT is complete, the FTSS in the channels that are part of the fault masking group shall [SRS239] report the results of IBIT for all Radstone boards to the application software for telemetry.
15.
In IBIT failure cases that cause processing to halt, the failure shall [SRS269] be handled as described in Section 3.2.6.2, Recovery.
16.
FTSS shall [SRS290], in ICP and FCP IBIT failure cases that allow processing to continue, after saving the results of IBIT for reporting to the application, in the first minor frame after Startup or recovery, consider the FCR to be failed, and start performing recovery actions for the FCR.
3.2.5.2 Continuous BIT Continuous BIT executes on the FCP at all times after initialization is complete.
In general, these tests execute system-wide tests using the fault tolerance characteristics of the FTPP architecture.
1.
Continuous BIT, in conjunction with Redundancy Management and Scheduler operations running in the 50 Hz rategroup after the application tasks, shall [SRS091] take less than 2 milliseconds under nominal no-fault conditions.
2.
Continuous BIT, in conjunction with Redundancy Management and Scheduler operations running in the 50 Hz rategroup after the application tasks, shall [SRS183] take less than 3 milliseconds while processing faults.
3.
Continuous BIT shall [SRS093] execute on the FCP virtual group.
4.
Continuous BIT shall [SRS094] reset the processor�s built-in watchdog timer at 50 Hz.
A failure to reset the watchdog timer within the allotted time (nominally 1.6 seconds) will generate a processor reset.
5.
Continuous BIT shall [SRS095] exercise the presence test at 50 Hz to ensure that all processors in the FCP virtual group are synchronized.
6.
The presence test shall [SRS184] also ascertain that all processors are executing the same 50 Hz, 10 Hz and 1 Hz frames.
7.
Continuous BIT shall [SRS096] diagnose the faulty FCR within 1 second after detecting a failure.
8.
Continuous BIT shall [SRS097] detect a failed ICP processor by detecting the absence of a periodic message for 2 consecutive minor cycles.
9.
Continuous BIT shall [SRS098] report all diagnosed failures and recovery actions to the application for incorporation in the telemetry stream.
3.2.5.3 RAM Scrub 1.
RAM scrub shall [SRS043] actively trigger the EDAC function by cyclically reading (and writing back if an error is found) all used RAM.
2.
RAM scrub shall [SRS044] report detected errors to the application, congruently on all channels, via an API service for inclusion in the telemetry stream.
3.
RAM scrub shall [SRS187] be capable of scrubbing at least 10 megabytes every 8 minutes, given at least 1% of the CPU is available for this processing.
4.
RAM scrub shall [SRS275] not scrub the area used for telemetry data.
3.2.6 Redundancy Management Redundancy Management maintains the mapping of physical hardware to virtual groups.
This capability reconfigures the mapping in response to a diagnosis of a failed component, which can be a failed processor, failed network element or a link failure.
Redundancy Management also performs transient fault analysis within constraints dictated by the mission management application software.
1.
Redundancy Management shall [SRS099] provide an API call to enable the application to retrieve the health status of the processors, network elements, network element links, MPCCs, and ICP controlled interfaces.
2.
Redundancy Management shall [SRS100] provide an API call to enable the application to request that the FTSS RM software initiate a voted reset of a channel.
3.
Redundancy Management shall [SRS201] be able to accommodate power up of all 5 channels and maintain all 5 NEs active, assuming no failures.
3.2.6.1 Virtual Group Configuration The virtual group configuration defines the mapping of physical hardware to virtual group(s).
It defines the redundancy of each virtual group and the location of the processors in the VME backplane.
This mapping of virtual group member(s) is maintained as an ordered pair of network element and port on the associated network element.
1.
Redundancy Management shall [SRS101] define an initial mapping of physical hardware to virtual group identifiers consisting of 1 quadruplex FCP virtual group and 5 ICP simplexes.
2.
If an FCR is diagnosed as faulty during Startup, Redundancy Management shall [SRS102] exclude the FCP in the faulty channel from the initial FCP virtual group configuration.
3.2.6.2 Recovery Redundancy Management configures the FCP virtual group, the network element, and the interconnection links for recovery of hardware resources in the operational system.
Redundancy Management determines the recovery strategy to be executed based upon current configuration and whether alignment is permitted.
When a fault occurs, the configuration will change.
The new configuration depends on the previous configuration.
All the possible configuration changes are shown in Figure 32.
Figure 32 Fault-down Map 1.
Redundancy Management shall [SRS104] implement the following strategies to reconfigure hardware resources: a) degrade the FCP virtual group, b) re-integrate an FCP processor into the FCP virtual group, c) re-integrate a Network Element, or d) mask a Network Element.
2.
When the FCP virtual group is configured as a quadruplex and a failed FCR other than the NEFU has been diagnosed, Redundancy Management shall [SRS106] degrade the FCP virtual group to triplex, removing the FCR.
The NE and the processors on the failed FCR will be removed from the NEs� Configuration Table (CT) and recovery of that channel will then take place, if alignment is permitted.
Note that a failed FCR could be diagnosed using any method, including (but not limited to) Continuous BIT, ICP presence test, or NE syndrome analysis.
3.
When the FCP virtual group is configured as a triplex, and if the NEFU is still active (4 NEs active total), and a failed FCR other than the NEFU has been diagnosed, Redundancy Management shall [SRS282] degrade the FCP virtual group to degraded triplex, removing the FCR.
The NE and the processors on the failed FCR will be removed from the NEs� Configuration Table (CT) and recovery of that channel will then take place, if alignment is permitted.
Note that a failed FCR could be diagnosed using any method, including (but not limited to) Continuous BIT, ICP presence test, or NE syndrome analysis.
4.
If the FCP is configured as a triplex, and if the NEFU is not still active (3 NEs active total), and another failure in the FCP FCR is diagnosed, Redundancy Management shall [SRS284] mask out the processors on the failed FCR.
The NE will remain in the CT and no recovery will take place.
Note that a failed FCR could be diagnosed using any method, including (but not limited to) Continuous BIT, ICP presence test, or NE syndrome analysis.
5.
If a failure in an FCR other than the NEFU is diagnosed when the FCP is configured as a degraded triplex, no action shall [SRS254] be taken.
Note that a failed FCR could be diagnosed using any method, including (but not limited to) Continuous BIT, ICP presence test, or NE syndrome analysis.
6.
For the NEFU, if the first failure is diagnosed, Redundancy Management shall [SRS245] issue a configuration update to mask out the failed processor.
Note that the NE is allowed to remain in the configuration and no recovery will take place.
Note also that the failed NEFU could be diagnosed using any method, including (but not limited to) ICP presence test, or NE syndrome analysis.
7.
For the NEFU, if errors are identified after the processor has been masked out, and if at least 4 NEs are still active, the NE shall [SRS283] be removed from the configuration and recovery will be attempted.
Note that the NEFU recovery does not depend on whether alignment is permitted.
8.
If the configuration needs to be changed due to a fault, as specified above, Redundancy Management shall [SRS128] issue a configuration update to mask out the failed network element.
9.
Redundancy Management shall [SRS109] degrade the FCP virtual group within 3 minor frames of fault detection and isolation.
Recovery consists of the following steps: 10.
Redundancy Management shall [SRS204] issue a voted reset to the failed channel, if alignment is permitted.
(Note that NEFU recovery does not depend on whether alignment is permitted.) 11.
Redundancy Management shall [SRS129] initiate transient NE recovery to restore Byzantine-resilient communications, if alignment is permitted.
(Note that NEFU recovery does not depend on whether alignment is permitted.) 12.
Redundancy Management shall [SRS110] reintegrate a failed FCP processor with the FCP virtual group when alignment is permitted and when the processor failure is not permanent.
13.
From the time that the FCR failure has been identified, if the components of the FCR are recoverable and alignment is permitted, to the time the FCR is recovered, shall [SRS205] be no more than 1.5 minutes.
14.
Redundancy Management shall [SRS208], within 60 milliseconds after 1.5 minutes has elapsed since the voted reset was sent to the failed channel, if the voted reset fails to recover the failed channel and alignment is still allowed, request from the application a power cycle of the channel.
(Note that NEFU recovery does not depend on whether alignment is permitted.) 15.
Redundancy Management shall [SRS209], within 60 milliseconds after 1.5 minutes has elapsed since the first power cycle request, if the FCR has not been recovered and alignment is still allowed, issue another request to the application for a power cycle of the channel.
(Note that NEFU recovery does not depend on whether alignment is permitted.) 16.
Redundancy Management shall [SRS211], if power cycle requests fail to result in a recovered channel, request the application to power down the channel and declare the channel to be permanently failed.
Note that the same result will occur if the application software ignores or fails to respond to power cycle requests.
17.
The application software shall [SRS285] have the capability to reset a permanently failed channel to its initial recovery state.
18.
Redundancy Management shall [SRS117] reintegrate a processor that is temporarily disabled during a time when alignment was not permitted, when alignment is subsequently permitted.
Redundancy Management picks up where it left off in these attempts.
For example, if Redundancy Management is at 1 minute in its 1.5 minute wait for a channel after the first power cycle request, and alignment is not allowed, when alignment is subsequently allowed Redundancy Management will wait another half minute and then try the next power cycle request.
19.
An API call shall [SRS274] be provided that allows the application to notify FTSS that an FCR is intentionally being powered down.
20.
Redundancy Management shall [SRS302] provide an API call to allow the application to specify whether recovery and alignment of failed FCRs is permitted.
Note that recovery of the NEFU is always considered to be permitted.
3.2.6.2.1 Recovery from Processor Failure This section deleted 3.2.6.2.1.1 Degrade Virtual Group This section deleted.
3.2.6.2.1.2 Reintegrate Processor When memory alignment is permitted, Redundancy Management attempts to reintegrate a processor with the other members of its original FCP virtual group by commanding the affected FCP virtual group to perform re-synchronization operations.
Redundancy Management aligns the memory, clocks, cache, and other internal registers of the failed processor after synchronization has been achieved.
1.
While synchronization is being attempted, the FCP virtual group shall [SRS123] maintain synchronous operations.
2.
Only when memory alignment is permitted, Redundancy Management shall [SRS124] initiate periodic re-synchronization attempts on the FCP virtual group at a 1 second rate.
3.
Redundancy Management shall [SRS125] perform memory alignment on a major frame boundary upon successful synchronization of all members of the FCP virtual group.
4.
Redundancy Management shall [SRS281], during memory alignment, configure the NE to mask out the processor being re-synchronized.
5.
Redundancy Management shall [SRS271] notify the application that alignment and reintegration of a processor will take place in 1 second.
6.
Redundancy Management shall [SRS272] wait for the ICP to signal that it has completed initialization before suspending the application for memory re-alignment.
7.
During alignment, Redundancy Management shall [SRS126] update MET (and, by extension, SEP).
8.
Redundancy Management shall [SRS214], if alignment is permitted, incorporate a new channel within 1.5 minutes after power is applied to the channel.
9.
Redundancy Management shall [SRS236], if alignment is permitted, serially incorporate two new channels if they are powered on simultaneously.
3.2.6.2.1.3 Data Management Three types of memory are defined: a) Congruent aligned	- always aligned b) Congruent initialized	- initialized from nonvolatile memory c) Non-congruent - never aligned 1.
The FTSS API shall [SRS046] define a methodology for segregating and managing congruent aligned, congruent initialized, and non-congruent memory such that congruent aligned memory is aligned and congruent initialized memory is initialized during channel recovery.
Non-congruent memory is not modified during realignment.
2.
The FTSS API shall [SRS217] specify a memory map that provides the boundaries for congruent aligned memory, congruent initialized memory, and non-congruent memory.
3.2.6.2.1.4 Memory Alignment Memory alignment occurs when a channel has been out of synchrony for some amount of time and then re-synchronizes with the other channels.
The amount of time the channel is out of synchrony depends on the recovery mechanism.
It could take as much as 4.5 minutes for the channel to be recovered and re-aligned (1.5 minutes per attempt for 3 attempts).
The channel that is being brought back into synchrony is the "target" channel.
1.
Memory alignment shall [SRS045] align processor state and congruent aligned memory locations.
Processor state includes all registers.
It also includes those timers used by FTSS.
2.
The re-align function shall [SRS186] write the voted value from the currently synchronized channels into the target channel.
3.
FTSS shall [SRS200] initialize congruent initialized memory locations from non-volatile memory.
4.
Memory alignment shall [SRS203] take no more than 1 second per Megabyte of data to be realigned.
5.
The FCP watchdog timer shall [SRS293] remain active during memory re-alignment.
6.
Memory alignment shall [SRS294] reset the watchdog timer such that, in the absence of a fault, the timer never expires and resets the processor.
3.2.6.2.2 Recovery from Link Failure This section deleted.
3.2.6.2.3 Recovery from Network Element Failure This section deleted.
3.2.7 Time Services 1.
Time Services shall [SRS142] provide Mission Elapsed Time and Separation Elapsed Time, with resolution partitioned as follows according to rate group, in order to guarantee identical copies of time representation across all FCPs: a) 50 Hz Mission Elapsed Time	20 milliseconds, b) 10 Hz Mission Elapsed Time	100 milliseconds, c) 1 Hz Mission Elapsed Time	1 second, d) 50 Hz Separation Elapsed Time	20 milliseconds, e) 10 Hz Separation Elapsed Time	100 milliseconds, and f) 1 Hz Separation Elapsed Time	1 second.
2.
The Mission Elapsed Time shall [SRS218] have a drift rate of at worst 50 PPM.
3.
The Mission Elapsed Time shall [SRS144] not rollover for 30 days.
4.
The Separation Elapsed Time shall [SRS145] not rollover for 1 day.
5.
The Mission Elapsed Time shall [SRS165] be initialized to zero at the first 50 Hz frame.
6.
The Separation Elapsed Time shall [SRS161] be initialized to zero at startup, and start counting up in the next frame after being notified via an API call that the X-38 vehicle has been released from the Space Shuttle Remote Manipulator System.
7.
The Separation Elapsed Time shall [SRS219] have a drift rate of at worst 50 PPM.
8.
Time Services shall [SRS246] provide a utility timer to the application.
Note that this timer is not voted, and must be assigned to a variable defined using non-congruent memory.
9.
The utility timer shall [SRS247] have an accuracy equal to or better than 50 PPM.
10.
The utility timer shall [SRS256] have a resolution equal to or better than 60.6 nanoseconds.
11.
The utility timer shall [SRS248] shall be set to zero prior to the first application task running in the first minor frame of each major frame.
3.2.8 System Support Services 3.2.8.1 CTC Requirements If transmission status indicates an error in telemetry and/or remote commanding operations 10 consecutive times, the following actions shall [SRS298] be taken: 1.
Support Services shall [SRS299] switch to the redundant MPCC device to continue telemetry and/or remote commanding operations.
Note that there are only two CTCs.
CTC1 is connected to FCC1 and FCC3.
CTC2 is connected to FCC2 and FCC4.
2.
Support Services shall [SRS242] continue to close and reopen a faulty MPCC device until status shows that the device has recovered.
3.
In all error cases, Support Services shall [SRS222] attempt to choose an error-free FCC-MPCC path, switching back and forth between channels if necessary.
4.
Support Services shall [SRS286] provide an API call which allows the application to specify which MPCC channels in a C&T FCR should be used for telemetry and/or command reception.
3.2.8.1.1 Telemetry Requirements The Telemetry Logging capability provides tasks with the capability for transmission to a telemetry-capturing device.
5.
The telemetry capability shall [SRS148] be capable of transferring 12,800 bytes within the 10 Hz frame from the FCP.
6.
The telemetry capability shall [SRS149] transfer the telemetry block from the FCP to the FCC-MPCC connected to the CTC.
7.
The telemetry capability shall [SRS150] signal the FCC-MPCC to transfer the telemetry block to the CTC.
8.
The telemetry capability shall [SRS300] provide status data to FTSS FDI about each FCC-MPCC RS-422 link to the CTC.
9.
Support Services shall [SRS151] provide an API call to specify the address and length of a telemetry buffer.
10.
Support Services shall [SRS257] use no more than 5.2 milliseconds of FCP processing time to move the telemetry data to the FCC-MPCC board and complete communication and error handling for the FCC-MPCC board.
3.2.8.1.2 Command Read Requirements 1.
The Command Read capability shall [SRS152] check for the presence of a command and status message from each CTC on each FCC-MPCC at 10hz.
2.
The Command Read capability on each FCP shall [SRS153] read the command data received from each CTC via the FCC-MPCC.
3.
FTSS shall [SRS304] provide status data to the application about each FCC-MPCC RS-422 link to the CTC used for command data.
4.
Support Services shall [SRS156] provide an API call to provide the current command data.
3.2.9 Power Down Services FTSS shall [SRS249] provide an API call which closes and deletes all rate groups, deletes all communication mechanisms (including any internal to FTSS), and then deletes all tasks.
3.3 CSCI External Interface Requirements 3.3.1 Interface Identification and Diagram The external interfaces to the FTSS CSCI are as follows: 1.
Application Programming Interface 2.
Network Element 3.
Radstone 4.
VxWorks 5.
Flight Critical Processor-Instrument Control Processor 6.
Multi-Processor Communications Controller These interfaces are shown in Figure 34 and elaborated further in subsequent paragraphs.
Figure 34 Fault Tolerant System Services CSCI External Interfaces.
3.3.2 IRIG-B/FTSS Interfaces This section deleted.
3.3.3 API/FTSS Interfaces The Application Programmer�s Interface (API) to Fault Tolerant System Services (FTSS) shall [SRS164] be as defined in the Application Programmer�s Interface, Draper Document #297752.
3.3.4 Network Element/FTSS Interfaces The Network Element (NE) provides fault tolerant communications among multiple virtual groups.
The virtual groups are computational sites composed of processors.
These processors may be configured as redundant virtual groups referred to as fault masking groups (FMGs) or as simplex virtual groups.
Fault masking groups may consist of 2, 3, or 4 processors that execute identical control streams.
A fault-masking group is composed of processors that reside in different fault-containment regions (FCR).
Each FCR contains a Network Element (NE) and either 1 or 2 Processors (an FCP member on all but the fifth NE chassis, and an ICP).
A simplex virtual group consists of a single processor.
All virtual groups communicate with each other via the network element.
The Network Elements provide communication between virtual groups, keep the FCRs synchronized, and maintain data consensus among FCRs.
The NEs are designed to implement the requirements for Byzantine resilience.
The Processing Elements are the computational sites.
Each processor consists of a microprocessor, private RAM and ROM, and miscellaneous support devices, such as timers.
Interfaces between the Network Elements and the FTSS are shown in Figure 36.
Figure 36.
Network Element Interfaces to FTSS CSCI.
All transactions with the Network Element consist of a Data Descriptor Block and a Data Block.
Each output transmission consists of an output descriptor block and an output data block.
Each input reception consists of an input descriptor block and an input data block.
The output descriptor and input descriptor blocks are defined in the Network Element Descriptor Block interfaces identified in Table 3.3-1.
The output and input data blocks are defined in the Network Element Data Block Interfaces identified in Table 3.3-2; the format of the data blocks differs with the type of message transmitted.
The table first identifies the type of message, and then provides the format of the data block for the given type.
Table 3.3-1.
Network Element Descriptor Block Interface.
3.3.5 Radstone/FTSS Interfaces The Radstone firmware provides BIT capability on all Radstone boards on power up or reset.
At the end of BIT the Radstone firmware saves the fault log.
Data element definitions for the Radstone/FTSS interface are shown in Table 3.3-3.
3.3.6 VxWorks/FTSS Interfaces For VxWorks/FTSS interfaces see VxWorks Reference Manual.
Appendix A of the API manual defines the allowable subset of VxWorks calls that can be safely used by the FCP application software.
3.3.7 Multi-Protocol Communications Controller (MPCC)/FTSS Interfaces For MPCC/FTSS interfaces see the Radstone MPCC01 Firmware Manual, Pub #YD681MPCC1, and Radstone MPCC01 Hardware Manual, Pub #HH681MPCC1.
The telemetry serial line on the MPCC cards will be configured as follows: * Mode: 0x1103 o SLDC Mode o Buffered Transfer o Single Frame Transfer o Report a Break character, but do not close the RX channel o Normal Operation * Note: CRC is always generated in SDLC mode * Baud Speed: 2,097,152 bps * Buffer size: 13,000 bytes * No parity, 1 stop bit, 8 bit chars: 0x80 The command serial line on the MPCC cards will be configured as follows: * Mode: 0x1103 o SLDC Mode o Buffered Transfer o Single Frame Transfer o Report a Break character, but do not close the RX channel o Normal Operation * Note: CRC is always generated in SDLC mode * Buffer size: 332 bytes * Baud Speed: 1,048,576 bps * No parity, 1 stop bit, 8 bit chars: 0x80 3.3.8 FCP-ICP/FTSS Interfaces The scheduler will populate shared memory with the data defined in Section 3.2.2.1, Item 21.
The scheduler will issue a VME interrupt to the ICP every FCP 50 Hz minor frame.
This interrupt will alert the ICP to enter a new ICP 50 Hz minor frame cycle.
The minor frame number the ICP should be executing on is denoted by the value of the minor_frame identifier in shared memory.
Data element definitions for the ICP/FCP FTSS interface are shown in Table 3.3-4.
3.4 CSCI Internal Interface Requirements There are no requirements for internal interfaces.
3.5 CSCI Internal Data Requirements There are no requirements for internal data.
3.6 Adaptation Requirements No requirements related to installation-dependent data or operational parameters have been identified.
3.7 Safety Requirements No safety requirements have been identified.
3.8 Security and Privacy Requirements No security requirements have been identified.
3.9 CSCI Environment Requirements See Section 3.10.3.
3.10 Computer Resource Requirements 3.10.1 Computer Hardware Requirements The FTSS shall [SRS158] execute on the Radstone Power PC 604R.
3.10.2 Computer Hardware Resource Utilization Requirements The FTSS software and the VxWorks operating system, together shall [SRS193] utilize no more than 3 megabytes of ROM.
The largest single block of data transmitted on the VME Bus by the FTSS shall [SRS223] transmit in no longer than 100 microseconds.
All FTSS data provided for telemetry (as specified in the requirements) shall [SRS250] fit within the allocated budget of 5000 bits per second.
In addition, the FTSS software shall [SRS280] provide up to 600 bits of start-up data that indicates the state of the FTPP system during start-up.
Note that CPU usage limits, where needed, have been included in each of the sections with the requirements for the services provided.
It is not possible to limit the total CPU usage of all services provided by the FTSS since the application calls the services an unknown number of times per major cycle.
3.10.3 Computer Software Requirements The FTSS software shall [SRS159] be written in the C programming language.
FTSS shall [SRS160] use the VxWorks Operating System version 5.4.
The FTSS software and the VxWorks operating system shall [SRS258] utilize no more than 9 Megabytes of DRAM code and data space.
Of the 9 Megabytes of DRAM allocation, only 4 Megabytes of FTSS/VxWork�s DRAM shall [SRS259] be re-aligned during any re-alignment attempts.
FTSS shall [SRS253] be compiled, linked and downloaded using Tornado 2 for the NT environment prior to delivery, for all engineering and formal releases.
FTSS object modules linked to the application on the four FCPs shall [SRS166] be identical.
After initial synchronization, the FCPs shall [SRS168] remain synchronized until a hardware fault occurs.
For example, asymmetric I/O calls will not be allowed to induce a large enough skew to force the FCPs to desynchronize.
3.10.4 Computer Communications Requirements NA 3.11 Software Quality Factors NA 3.12 Design and Implementation Constraints See Section 3.10.3.
3.13 Personnel-related Requirements No personnel-related requirements have been identified.
3.14 Training-related Requirements No training-related requirements have been identified.
3.15 Logistics-related Requirements NA 3.16 Other Requirements This section contains the requirements for the ICP.
3.16.1 ICP Services FTSS shall [SRS303] provide an API call to allow the ICP application to determine on which channel it resides.
FTSS shall [SRS225] provide an API call to allow applications to send a status message to FDIR running on the FCP.
FTSS shall [SRS226] provide "immediate" message passing services in the form of "pipes".
"Pipes" provide fast data throughput between virtual groups or within a virtual group when minimal data latency is necessary.
FTSS shall [SRS227] route messages to the proper virtual group(s) and socket.
If there is insufficient space to enqueue a message for transmission, FTSS shall [SRS228] return an error to the corresponding task.
Sockets are non-blocking and place the burden of polling on the application task.
FTSS shall [SRS229] provide the following error handling information as feedback to the "pipe" API calls: a) notification of invalid or out of range application specified parameters on all operations, b) pipe "open" of end point ( SENDER/RECEIVER ) by non-assigned virtual group, c) notification upon receiving a message that the previous message was overwritten, d) connection/transmission error, e) FTSS unable to create/open pipe, and f) notification that a received message was truncated to the buffer size provided.
FTSS shall [SRS230] only allow a single task residing on each specified virtual group to "open" the respective end of the pipe.
The presence or absence of an NEFU ICP shall [SRS220] not impact the FTSS software (i.e.
the FTSS ICP load will not be different).
The FTSS shall [SRS231] provide an API call to retrieve the current minor frame number sent from the FCP over the VME interface.
Note that the NEFU ICP will not have this information since it does not have an FCP processor.
The FTSS shall [SRS232] provide an API call to retrieve the current MET value sent from the FCP over the VME interface.
Note that the NEFU ICP will not have this information since it does not have an FCP processor.
The FTSS shall [SRS233] provide an API call to retrieve the current SEP value sent from the FCP over the VME interface.
Note that the NEFU ICP will not have this information since it does not have an FCP processor.
The FTSS shall [SRS295] notify the application on the ICP, via an API call, 2 minor frames prior to an alignment.
3.17 Packaging Requirements FTSS deliveries shall [SRS252] be made using CD ROM media.
3.18 Precedence and Criticality of Requirements No precedence or criticality of requirements has been identified.
4.
QUALIFICATION PROVISIONS The following qualification methods will be used for the FTSS software.
Demonstration (D) - The operation of the CSCI (or some part of the CSCI) to observe its functional operation.
The functional operation is directly observable, and it requires no elaborate instrumentation or special test equipment.
Test (T) - The operation of the CSCI (or a part of the CSCI) using instrumentation or other special test equipment to collect data for later analysis.
Analysis (A) - The processing of data accumulated from other qualification methods to determine correct results (e.g., interpretation of data collected by special test equipment).
Inspection (I) - The visual examination of CSCI code, documentation, etc.
The qualification methods that will be used for each software requirement are specified in the Certification Test Procedures document.
297749 Rev F 12 March 2002 ii 297749 Rev F 12 March 2002 Total pages: 98 3 